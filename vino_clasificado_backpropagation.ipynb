{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "GeH-LRoS6mHM",
        "outputId": "13cb7393-cf72-4726-f2a2-531410eb4e97"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-60e7754f-af46-4e02-9fbb-5edb15e63a4b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-60e7754f-af46-4e02-9fbb-5edb15e63a4b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-3283157670.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 1. Cargar el dataset desde archivo CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# ===========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Abre una ventana para subir archivos y guarda el resultado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Obtiene el nombre del primer archivo subido\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np # Importa la librer铆a NumPy para operaciones num茅ricas\n",
        "from google.colab import files # Importa la funci贸n files de google.colab para cargar archivos\n",
        "\n",
        "# ===========================\n",
        "# 1. Cargar el dataset desde archivo CSV\n",
        "# ===========================\n",
        "uploaded = files.upload() # Abre una ventana para subir archivos y guarda el resultado\n",
        "filename = list(uploaded.keys())[0] # Obtiene el nombre del primer archivo subido\n",
        "\n",
        "# Leer l铆neas del archivo\n",
        "with open(filename, 'r') as f: # Abre el archivo subido en modo lectura\n",
        "    lines = f.readlines() # Lee todas las l铆neas del archivo en una lista\n",
        "\n",
        "# Leer encabezado y determinar qu茅 columnas excluir\n",
        "header = lines[0].strip().split(';') # Lee la primera l铆nea (encabezado), elimina espacios extra y divide por ';'\n",
        "col_excluir = [\"free sulfur dioxide\", \"density\"] # Define una lista de nombres de columnas a excluir\n",
        "\n",
        "# ndices de columnas a excluir\n",
        "# Crea una lista de 铆ndices de las columnas cuyo nombre (ignorando may煤sculas y espacios)\n",
        "# est谩 en la lista col_excluir\n",
        "idx_excluir = [i for i, col in enumerate(header) if col.lower().strip() in [c.lower() for c in col_excluir]]\n",
        "\n",
        "# ndices a mantener (todas excepto las excluidas y la 煤ltima)\n",
        "# Crea una lista de 铆ndices para las columnas a incluir, excluyendo las de idx_excluir\n",
        "# y la 煤ltima columna (que es el target)\n",
        "idx_incluir = [i for i in range(len(header)) if i not in idx_excluir and i != len(header)-1]\n",
        "idx_target = len(header) - 1  # El 铆ndice de la 煤ltima columna (la variable objetivo 'quality')\n",
        "\n",
        "# Procesar filas v谩lidas\n",
        "data_limpia = [] # Inicializa una lista vac铆a para almacenar los datos limpios\n",
        "for line in lines[1:]: # Itera sobre cada l铆nea del archivo, empezando desde la segunda l铆nea (despu茅s del encabezado)\n",
        "    fila = line.strip().split(';') # Elimina espacios extra de la l铆nea y la divide por ';'\n",
        "\n",
        "    # Verifica si la fila tiene el n煤mero correcto de columnas y si ninguna celda est谩 vac铆a\n",
        "    if len(fila) == len(header) and all(cell.strip() != '' for cell in fila):\n",
        "        try:\n",
        "            # Intenta convertir todos los valores de la fila a float\n",
        "            fila_float = [float(cell) for cell in fila]\n",
        "            data_limpia.append(fila_float) # Si la conversi贸n es exitosa, a帽ade la fila a data_limpia\n",
        "        except ValueError:\n",
        "            continue # Si hay un error de conversi贸n (no es un n煤mero), ignora la fila\n",
        "\n",
        "# Convertir a NumPy\n",
        "data = np.array(data_limpia, dtype=np.float32) # Convierte la lista de listas data_limpia a un array de NumPy con tipo float32\n",
        "\n",
        "# ===========================\n",
        "# 2. Separar caracter铆sticas (X) y variable objetivo (y)\n",
        "# ===========================\n",
        "X = data[:, idx_incluir] # Selecciona todas las filas y las columnas especificadas en idx_incluir para las caracter铆sticas (X)\n",
        "y = data[:, idx_target].astype(int) # Selecciona todas las filas y la columna del target, y la convierte a tipo entero\n",
        "\n",
        "print(\"Shape de X:\", X.shape) # Imprime la forma (dimensiones) del array X\n",
        "print(\"Columnas utilizadas (sin las excluidas):\", [header[i] for i in idx_incluir]) # Imprime los nombres de las columnas usadas como caracter铆sticas\n",
        "print(\"Primeras 5 muestras de X:\\n\", X[:5]) # Imprime las primeras 5 filas del array X\n",
        "print(\"Valores 煤nicos en y:\\n\", np.unique(y)) # Imprime los valores 煤nicos presentes en la variable objetivo y\n",
        "\n",
        "# ===========================\n",
        "# 3. Normalizaci贸n (Z-score)\n",
        "# ===========================\n",
        "mean = np.mean(X, axis=0) # Calcula la media de cada columna en X\n",
        "std = np.std(X, axis=0) # Calcula la desviaci贸n est谩ndar de cada columna en X\n",
        "X_normalized = (X - mean) / std # Aplica la normalizaci贸n Z-score: (valor - media) / desviaci贸n est谩ndar\n",
        "\n",
        "# ===========================\n",
        "# 4. Codificaci贸n One-Hot para salida\n",
        "# ===========================\n",
        "clases_unicas = np.sort(np.unique(y)) # Obtiene los valores 煤nicos en y y los ordena\n",
        "num_clases = len(clases_unicas) # Cuenta el n煤mero de clases 煤nicas\n",
        "# Crea un diccionario que mapea cada valor de clase 煤nico a un 铆ndice (0, 1, 2, ...)\n",
        "class_to_index = {label: idx for idx, label in enumerate(clases_unicas)}\n",
        "y_index = np.array([class_to_index[val] for val in y]) # Convierte cada valor de y a su 铆ndice correspondiente usando el diccionario\n",
        "y_onehot = np.zeros((len(y_index), num_clases)) # Crea una matriz de ceros con tantas filas como muestras y tantas columnas como clases\n",
        "y_onehot[np.arange(len(y_index)), y_index] = 1 # Realiza la codificaci贸n One-Hot: pone un 1 en la posici贸n del 铆ndice de la clase para cada muestra\n",
        "\n",
        "print(\"Ejemplo de salida (y) original:\\n\", y[:5]) # Imprime las primeras 5 muestras de la variable objetivo original\n",
        "print(\"One-hot encoded:\\n\", y_onehot[:5]) # Imprime las primeras 5 muestras de la variable objetivo despu茅s de la codificaci贸n One-Hot\n",
        "\n",
        "# ===========================\n",
        "# 5. Mezclar y dividir en entrenamiento y prueba\n",
        "# ===========================\n",
        "np.random.seed(42)  # Establece una semilla para el generador de n煤meros aleatorios para reproducibilidad\n",
        "indices = np.arange(len(X_normalized)) # Crea un array de 铆ndices desde 0 hasta el n煤mero de muestras - 1\n",
        "np.random.shuffle(indices)  # Mezcla aleatoriamente los 铆ndices\n",
        "X_shuffled = X_normalized[indices] # Reordena las filas de X_normalized seg煤n los 铆ndices mezclados\n",
        "y_shuffled = y_onehot[indices] # Reordena las filas de y_onehot seg煤n los mismos 铆ndices mezclados\n",
        "\n",
        "# 60% entrenamiento\n",
        "train_size = int(0.6 * len(X_shuffled)) # Calcula el tama帽o del conjunto de entrenamiento (60%)\n",
        "X_train = X_shuffled[:train_size] # Selecciona las primeras 'train_size' filas para el conjunto de entrenamiento X\n",
        "y_train = y_shuffled[:train_size] # Selecciona las primeras 'train_size' filas para el conjunto de entrenamiento y\n",
        "X_test = X_shuffled[train_size:] # Selecciona las filas restantes para el conjunto de prueba X\n",
        "y_test = y_shuffled[train_size:] # Selecciona las filas restantes para el conjunto de prueba y\n",
        "\n",
        "# ===========================\n",
        "# Resumen final\n",
        "# ===========================\n",
        "print(\"Tama帽o entrenamiento:\", X_train.shape, y_train.shape) # Imprime las dimensiones de los conjuntos de entrenamiento\n",
        "print(\"Tama帽o validaci贸n/prueba:\", X_test.shape, y_test.shape) # Imprime las dimensiones de los conjuntos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiDdbu-Z1PIo",
        "outputId": "944dad7b-9dc2-46fe-85b8-758c1f923330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "poca 0 | P茅rdida: 1.7926 | Precisi贸n: 19.22%\n",
            "poca 100 | P茅rdida: 1.4505 | Precisi贸n: 35.54%\n",
            "poca 200 | P茅rdida: 1.1668 | Precisi贸n: 52.74%\n",
            "poca 300 | P茅rdida: 1.0359 | Precisi贸n: 56.12%\n",
            "poca 400 | P茅rdida: 0.9537 | Precisi贸n: 60.81%\n",
            "poca 500 | P茅rdida: 0.9070 | Precisi贸n: 62.73%\n",
            "poca 600 | P茅rdida: 0.8705 | Precisi贸n: 65.07%\n",
            "poca 700 | P茅rdida: 0.8398 | Precisi贸n: 67.60%\n",
            "poca 800 | P茅rdida: 0.8126 | Precisi贸n: 69.06%\n",
            "poca 900 | P茅rdida: 0.7868 | Precisi贸n: 69.10%\n",
            "poca 1000 | P茅rdida: 0.7642 | Precisi贸n: 69.34%\n",
            "poca 1100 | P茅rdida: 0.7440 | Precisi贸n: 69.29%\n",
            "poca 1200 | P茅rdida: 0.7264 | Precisi贸n: 70.56%\n",
            "poca 1300 | P茅rdida: 0.7117 | Precisi贸n: 70.70%\n",
            "poca 1400 | P茅rdida: 0.6985 | Precisi贸n: 71.17%\n",
            "poca 1500 | P茅rdida: 0.6868 | Precisi贸n: 71.45%\n",
            "poca 1600 | P茅rdida: 0.6758 | Precisi贸n: 71.82%\n",
            "poca 1700 | P茅rdida: 0.6650 | Precisi贸n: 72.76%\n",
            "poca 1800 | P茅rdida: 0.6542 | Precisi贸n: 72.86%\n",
            "poca 1900 | P茅rdida: 0.6437 | Precisi贸n: 73.79%\n",
            "poca 2000 | P茅rdida: 0.6334 | Precisi贸n: 74.17%\n",
            "poca 2100 | P茅rdida: 0.6231 | Precisi贸n: 74.12%\n",
            "poca 2200 | P茅rdida: 0.6129 | Precisi贸n: 74.68%\n",
            "poca 2300 | P茅rdida: 0.6023 | Precisi贸n: 74.92%\n",
            "poca 2400 | P茅rdida: 0.5900 | Precisi贸n: 75.15%\n",
            "poca 2500 | P茅rdida: 0.5789 | Precisi贸n: 75.34%\n",
            "poca 2600 | P茅rdida: 0.5675 | Precisi贸n: 76.84%\n",
            "poca 2700 | P茅rdida: 0.5563 | Precisi贸n: 77.59%\n",
            "poca 2800 | P茅rdida: 0.5467 | Precisi贸n: 78.53%\n",
            "poca 2900 | P茅rdida: 0.5433 | Precisi贸n: 78.39%\n",
            "poca 3000 | P茅rdida: 0.5380 | Precisi贸n: 77.59%\n",
            "poca 3100 | P茅rdida: 0.5290 | Precisi贸n: 77.64%\n",
            "poca 3200 | P茅rdida: 0.5237 | Precisi贸n: 77.64%\n",
            "poca 3300 | P茅rdida: 0.5176 | Precisi贸n: 77.26%\n",
            "poca 3400 | P茅rdida: 0.5109 | Precisi贸n: 78.06%\n",
            "poca 3500 | P茅rdida: 0.5037 | Precisi贸n: 78.43%\n",
            "poca 3600 | P茅rdida: 0.4986 | Precisi贸n: 78.76%\n",
            "poca 3700 | P茅rdida: 0.4918 | Precisi贸n: 79.23%\n",
            "poca 3800 | P茅rdida: 0.4851 | Precisi贸n: 79.42%\n",
            "poca 3900 | P茅rdida: 0.4769 | Precisi贸n: 80.22%\n",
            "poca 4000 | P茅rdida: 0.4707 | Precisi贸n: 80.36%\n",
            "poca 4100 | P茅rdida: 0.4649 | Precisi贸n: 80.59%\n",
            "poca 4200 | P茅rdida: 0.4575 | Precisi贸n: 80.92%\n",
            "poca 4300 | P茅rdida: 0.4512 | Precisi贸n: 81.53%\n",
            "poca 4400 | P茅rdida: 0.4461 | Precisi贸n: 81.81%\n",
            "poca 4500 | P茅rdida: 0.4403 | Precisi贸n: 81.90%\n",
            "poca 4600 | P茅rdida: 0.4346 | Precisi贸n: 82.23%\n",
            "poca 4700 | P茅rdida: 0.4289 | Precisi贸n: 82.37%\n",
            "poca 4800 | P茅rdida: 0.4251 | Precisi贸n: 82.42%\n",
            "poca 4900 | P茅rdida: 0.4197 | Precisi贸n: 83.54%\n",
            "poca 5000 | P茅rdida: 0.4154 | Precisi贸n: 83.73%\n",
            "poca 5100 | P茅rdida: 0.3886 | Precisi贸n: 85.19%\n",
            "poca 5200 | P茅rdida: 0.3858 | Precisi贸n: 85.61%\n",
            "poca 5300 | P茅rdida: 0.3832 | Precisi贸n: 85.61%\n",
            "poca 5400 | P茅rdida: 0.3806 | Precisi贸n: 85.65%\n",
            "poca 5500 | P茅rdida: 0.3782 | Precisi贸n: 85.75%\n",
            "poca 5600 | P茅rdida: 0.3757 | Precisi贸n: 86.12%\n",
            "poca 5700 | P茅rdida: 0.3732 | Precisi贸n: 86.08%\n",
            "poca 5800 | P茅rdida: 0.3709 | Precisi贸n: 85.98%\n",
            "poca 5900 | P茅rdida: 0.3685 | Precisi贸n: 85.75%\n",
            "poca 6000 | P茅rdida: 0.3662 | Precisi贸n: 85.89%\n",
            "poca 6100 | P茅rdida: 0.3640 | Precisi贸n: 85.75%\n",
            "poca 6200 | P茅rdida: 0.3617 | Precisi贸n: 85.75%\n",
            "poca 6300 | P茅rdida: 0.3595 | Precisi贸n: 85.79%\n",
            "poca 6400 | P茅rdida: 0.3574 | Precisi贸n: 85.84%\n",
            "poca 6500 | P茅rdida: 0.3554 | Precisi贸n: 85.79%\n",
            "poca 6600 | P茅rdida: 0.3533 | Precisi贸n: 85.79%\n",
            "poca 6700 | P茅rdida: 0.3512 | Precisi贸n: 86.17%\n",
            "poca 6800 | P茅rdida: 0.3490 | Precisi贸n: 86.31%\n",
            "poca 6900 | P茅rdida: 0.3467 | Precisi贸n: 86.50%\n",
            "poca 7000 | P茅rdida: 0.3446 | Precisi贸n: 86.54%\n",
            "poca 7100 | P茅rdida: 0.3427 | Precisi贸n: 86.59%\n",
            "poca 7200 | P茅rdida: 0.3409 | Precisi贸n: 86.73%\n",
            "poca 7300 | P茅rdida: 0.3392 | Precisi贸n: 86.78%\n",
            "poca 7400 | P茅rdida: 0.3371 | Precisi贸n: 86.73%\n",
            "poca 7500 | P茅rdida: 0.3354 | Precisi贸n: 86.87%\n",
            "poca 7600 | P茅rdida: 0.3336 | Precisi贸n: 86.78%\n",
            "poca 7700 | P茅rdida: 0.3319 | Precisi贸n: 86.92%\n",
            "poca 7800 | P茅rdida: 0.3302 | Precisi贸n: 87.01%\n",
            "poca 7900 | P茅rdida: 0.3285 | Precisi贸n: 87.15%\n"
          ]
        }
      ],
      "source": [
        "# === Funciones de activaci贸n ===\n",
        "# Implementa la funci贸n de activaci贸n ReLU (Rectified Linear Unit)\n",
        "def relu(x):\n",
        "    return np.maximum(0, x) # Devuelve el m谩ximo entre 0 y el valor de entrada (si es negativo, se vuelve 0)\n",
        "\n",
        "# Implementa la derivada de la funci贸n ReLU, necesaria para la retropropagaci贸n\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).astype(float) # Devuelve 1.0 si la entrada es mayor que 0, y 0.0 si es menor o igual a 0\n",
        "\n",
        "# Implementa la funci贸n de activaci贸n Softmax, utilizada en la capa de salida para problemas de clasificaci贸n multiclase\n",
        "def softmax(x):\n",
        "    # Resta el m谩ximo de cada fila para mejorar la estabilidad num茅rica y evitar la explosi贸n de valores\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    # Normaliza los valores exponenciados para que sumen 1 a lo largo de cada fila (probabilidades)\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "# === Inicializaci贸n de pesos y sesgos ===\n",
        "# Define el tama帽o de la capa de entrada (n煤mero de caracter铆sticas)\n",
        "input_size = X_train.shape[1]         # Ej: 11 si quitaste columnas\n",
        "# Define el tama帽o de la primera capa oculta\n",
        "hidden1_size = 16\n",
        "# Define el tama帽o de la segunda capa oculta\n",
        "hidden2_size = 32\n",
        "# Define el tama帽o de la capa de salida (n煤mero de clases)\n",
        "output_size = y_train.shape[1]        # 6 clases (one-hot)\n",
        "\n",
        "# Establece una semilla para el generador de n煤meros aleatorios para asegurar la reproducibilidad de la inicializaci贸n\n",
        "np.random.seed(1)\n",
        "# Inicializa los pesos de la primera capa con valores aleatorios peque帽os para evitar gradientes explosivos/desvanecientes\n",
        "W1 = np.random.randn(input_size, hidden1_size) * 0.1\n",
        "# Inicializa los sesgos de la primera capa con ceros\n",
        "b1 = np.zeros((1, hidden1_size))\n",
        "\n",
        "# Inicializa los pesos de la segunda capa oculta\n",
        "W2 = np.random.randn(hidden1_size, hidden2_size) * 0.1\n",
        "# Inicializa los sesgos de la segunda capa oculta\n",
        "b2 = np.zeros((1, hidden2_size))\n",
        "\n",
        "# Inicializa los pesos de la capa de salida\n",
        "W3 = np.random.randn(hidden2_size, output_size) * 0.1\n",
        "# Inicializa los sesgos de la capa de salida\n",
        "b3 = np.zeros((1, output_size))\n",
        "\n",
        "# === Hiperpar谩metros ===\n",
        "# Define el n煤mero de 茅pocas (iteraciones completas sobre todo el conjunto de entrenamiento)\n",
        "epochs = 8000\n",
        "# Define la tasa de aprendizaje, que controla el tama帽o de los pasos durante la actualizaci贸n de pesos\n",
        "learning_rate = 0.1\n",
        "\n",
        "# === Historial ===\n",
        "# Lista para almacenar el valor de la funci贸n de p茅rdida en cada 茅poca\n",
        "loss_history = []\n",
        "# Lista para almacenar la precisi贸n (accuracy) en el conjunto de entrenamiento en cada 茅poca\n",
        "accuracy_history = []\n",
        "\n",
        "# === Entrenamiento ===\n",
        "# Bucle principal de entrenamiento que itera a trav茅s del n煤mero de 茅pocas\n",
        "for epoch in range(epochs):\n",
        "    # --- FORWARD PASS ---\n",
        "    # Calcula la entrada a la primera capa oculta (multiplicaci贸n matricial de X_train y W1, m谩s el sesgo b1)\n",
        "    Z1 = X_train @ W1 + b1\n",
        "    # Aplica la funci贸n de activaci贸n ReLU a la salida de la primera capa oculta\n",
        "    A1 = relu(Z1)\n",
        "\n",
        "    # Calcula la entrada a la segunda capa oculta\n",
        "    Z2 = A1 @ W2 + b2\n",
        "    # Aplica la funci贸n de activaci贸n ReLU a la salida de la segunda capa oculta\n",
        "    A2 = relu(Z2)\n",
        "\n",
        "    # Calcula la entrada a la capa de salida\n",
        "    Z3 = A2 @ W3 + b3\n",
        "    # Aplica la funci贸n de activaci贸n Softmax a la salida de la capa de salida para obtener probabilidades\n",
        "    A3 = softmax(Z3)\n",
        "\n",
        "    # --- FUNCIN DE PRDIDA (Cross-Entropy) ---\n",
        "    # Calcula la p茅rdida de entrop铆a cruzada, com煤n para problemas de clasificaci贸n multiclase\n",
        "    # np.sum(y_train * np.log(A3 + 1e-8), axis=1) calcula la p茅rdida para cada muestra\n",
        "    # -np.mean(...) calcula el promedio de la p茅rdida sobre todas las muestras del lote de entrenamiento\n",
        "    loss = -np.mean(np.sum(y_train * np.log(A3 + 1e-8), axis=1)) # Se a帽ade un peque帽o valor (1e-8) para evitar logaritmo de cero\n",
        "    # Almacena el valor de la p茅rdida en el historial\n",
        "    loss_history.append(loss)\n",
        "\n",
        "    # --- ACCURACY ---\n",
        "    # Obtiene las clases predichas tomando el 铆ndice del valor m谩ximo en la salida de Softmax (A3)\n",
        "    y_pred_train = np.argmax(A3, axis=1)\n",
        "    # Obtiene las clases verdaderas tomando el 铆ndice del valor m谩ximo en la codificaci贸n One-Hot (y_train)\n",
        "    y_true_train = np.argmax(y_train, axis=1)\n",
        "    # Calcula la precisi贸n comparando las clases predichas con las verdaderas\n",
        "    acc_train = np.mean(y_pred_train == y_true_train)\n",
        "    # Almacena la precisi贸n en el historial\n",
        "    accuracy_history.append(acc_train)\n",
        "\n",
        "    # --- BACKPROPAGATION ---\n",
        "    # Calcula el gradiente de la p茅rdida con respecto a la entrada de la capa de salida (Z3)\n",
        "    dZ3 = A3 - y_train\n",
        "    # Calcula el gradiente de la p茅rdida con respecto a los pesos de la capa de salida (W3)\n",
        "    dW3 = A2.T @ dZ3\n",
        "    # Calcula el gradiente de la p茅rdida con respecto a los sesgos de la capa de salida (b3)\n",
        "    db3 = np.sum(dZ3, axis=0, keepdims=True)\n",
        "\n",
        "    # Calcula el gradiente de la p茅rdida con respecto a la salida de la segunda capa oculta (A2)\n",
        "    dA2 = dZ3 @ W3.T\n",
        "    # Calcula el gradiente de la p茅rdida con respecto a la entrada de la segunda capa oculta (Z2), aplicando la derivada de ReLU\n",
        "    dZ2 = dA2 * relu_derivative(Z2)\n",
        "    # Calcula el gradiente de la p茅rdida con respecto a los pesos de la segunda capa oculta (W2)\n",
        "    dW2 = A1.T @ dZ2\n",
        "    # Calcula el gradiente de la p茅rdida con respecto a los sesgos de la segunda capa oculta (b2)\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
        "\n",
        "    # Calcula el gradiente de la p茅rdida con respecto a la salida de la primera capa oculta (A1)\n",
        "    dA1 = dZ2 @ W2.T\n",
        "    # Calcula el gradiente de la p茅rdida con respecto a la entrada de la primera capa oculta (Z1), aplicando la derivada de ReLU\n",
        "    dZ1 = dA1 * relu_derivative(Z1)\n",
        "    # Calcula el gradiente de la p茅rdida con respecto a los pesos de la primera capa oculta (W1)\n",
        "    dW1 = X_train.T @ dZ1\n",
        "    # Calcula el gradiente de la p茅rdida con respecto a los sesgos de la primera capa oculta (b1)\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
        "\n",
        "    # --- ACTUALIZACIN DE PESOS ---\n",
        "    # Actualiza los pesos y sesgos de la capa de salida utilizando el descenso de gradiente\n",
        "    # Se divide por el n煤mero de muestras (X_train.shape[0]) para obtener el gradiente promedio del lote\n",
        "    W3 -= learning_rate * dW3 / X_train.shape[0]\n",
        "    b3 -= learning_rate * db3 / X_train.shape[0]\n",
        "    # Actualiza los pesos y sesgos de la segunda capa oculta\n",
        "    W2 -= learning_rate * dW2 / X_train.shape[0]\n",
        "    b2 -= learning_rate * db2 / X_train.shape[0]\n",
        "    # Actualiza los pesos y sesgos de la primera capa oculta\n",
        "    W1 -= learning_rate * dW1 / X_train.shape[0]\n",
        "    b1 -= learning_rate * db1 / X_train.shape[0]\n",
        "\n",
        "    # --- Ajuste de Learning Rate ---\n",
        "    if epoch > 5000 and epoch <= 6500:\n",
        "        learning_rate = 0.05\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # --- Mostrar progreso ---\n",
        "    # Imprime el progreso del entrenamiento (茅poca, p茅rdida y precisi贸n) cada 100 茅pocas\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"poca {epoch} | P茅rdida: {loss:.4f} | Precisi贸n: {acc_train * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ss3V8okBQLs",
        "outputId": "0feb35e9-8cf5-462f-bd8f-665ac939c07a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Precisi贸n (accuracy) del modelo: 81.22%\n",
            "\n",
            " Matriz de Confusi贸n (filas: real, columnas: predicho):\n",
            "[[277   0   0   0   0   0]\n",
            " [  0 266   3   3   0   0]\n",
            " [  6  17 177  63   8   0]\n",
            " [  0  13  70 129  23  12]\n",
            " [  1   3   6  30  21   9]\n",
            " [  0   0   0   0   0 285]]\n",
            "\n",
            "Ejemplos de predicci贸n:\n",
            "Vino 1: Real = 8, Predicho = 8\n",
            "Vino 2: Real = 3, Predicho = 3\n",
            "Vino 3: Real = 4, Predicho = 4\n",
            "Vino 4: Real = 3, Predicho = 3\n",
            "Vino 5: Real = 8, Predicho = 8\n",
            "Vino 6: Real = 8, Predicho = 8\n",
            "Vino 7: Real = 3, Predicho = 3\n",
            "Vino 8: Real = 8, Predicho = 8\n",
            "Vino 9: Real = 6, Predicho = 6\n",
            "Vino 10: Real = 5, Predicho = 5\n"
          ]
        }
      ],
      "source": [
        "# === EVALUACIN ===\n",
        "\n",
        "# 1. Hacer forward pass con los datos de prueba\n",
        "# Calcula la entrada a la primera capa oculta usando los datos de prueba (X_test)\n",
        "Z1_test = X_test @ W1 + b1\n",
        "# Aplica la funci贸n de activaci贸n ReLU a la salida de la primera capa oculta en el conjunto de prueba\n",
        "A1_test = relu(Z1_test)\n",
        "\n",
        "# Calcula la entrada a la segunda capa oculta usando la salida de la capa anterior (A1_test)\n",
        "Z2_test = A1_test @ W2 + b2\n",
        "# Aplica la funci贸n de activaci贸n ReLU a la salida de la segunda capa oculta en el conjunto de prueba\n",
        "A2_test = relu(Z2_test)\n",
        "\n",
        "# Calcula la entrada a la capa de salida usando la salida de la capa anterior (A2_test)\n",
        "Z3_test = A2_test @ W3 + b3\n",
        "# Aplica la funci贸n de activaci贸n Softmax a la salida de la capa de salida para obtener probabilidades de predicci贸n\n",
        "A3_test = softmax(Z3_test)\n",
        "\n",
        "# 2. Obtener clases predichas y verdaderas\n",
        "# Obtiene las clases predichas tomando el 铆ndice del valor m谩ximo en la salida de Softmax (A3_test) para cada muestra\n",
        "y_pred = np.argmax(A3_test, axis=1)\n",
        "# Obtiene las clases verdaderas tomando el 铆ndice del valor m谩ximo en la codificaci贸n One-Hot (y_test) para cada muestra\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# 3. Calcular accuracy\n",
        "# Calcula la precisi贸n comparando las clases predichas (y_pred) con las clases verdaderas (y_true)\n",
        "accuracy = np.mean(y_pred == y_true)\n",
        "# Imprime la precisi贸n del modelo en el conjunto de prueba, formateada a dos decimales\n",
        "print(f\"\\n Precisi贸n (accuracy) del modelo: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 4. Matriz de confusi贸n\n",
        "conf_matrix = np.zeros((6, 6), dtype=int)  # Inicializa una matriz de ceros de tama帽o 6x6 (para 6 clases) con tipo entero\n",
        "\n",
        "# Itera sobre cada muestra en el conjunto de prueba\n",
        "for i in range(len(y_true)):\n",
        "    true_class = y_true[i] # Obtiene la clase verdadera de la muestra actual\n",
        "    pred_class = y_pred[i] # Obtiene la clase predicha de la muestra actual\n",
        "    conf_matrix[true_class, pred_class] += 1 # Incrementa el contador en la matriz de confusi贸n en la posici贸n (clase_verdadera, clase_predicha)\n",
        "\n",
        "# Imprime la matriz de confusi贸n con una etiqueta explicativa\n",
        "print(\"\\n Matriz de Confusi贸n (filas: real, columnas: predicho):\")\n",
        "print(conf_matrix) # Imprime la matriz de confusi贸n calculada\n",
        "\n",
        "# 5. Mostrar algunas predicciones\n",
        "print(\"\\nEjemplos de predicci贸n:\")\n",
        "# Itera sobre las primeras 10 muestras del conjunto de prueba\n",
        "for i in range(10):\n",
        "    real = y_true[i] # Obtiene la clase verdadera (铆ndice)\n",
        "    pred = y_pred[i] # Obtiene la clase predicha (铆ndice)\n",
        "    # Imprime la clase verdadera y predicha para cada ejemplo, sumando 3 para mostrar las clases originales (3 a 8)\n",
        "    print(f\"Vino {i+1}: Real = {real + 3}, Predicho = {pred + 3}\")  # sumamos 3 para volver a clases reales"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
